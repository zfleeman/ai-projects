"""
Helper functions that interact with OpenAI
"""

from configparser import ConfigParser
from datetime import datetime
from pathlib import Path
from typing import Optional, Tuple
from urllib.request import Request, urlopen

from discord import Embed
from openai import AsyncOpenAI
from openai.types.responses import Response

from db_utils import CommandContext, get_api_key, get_response_id, update_chat


def get_config():
    """
    Read the configuration specified in the config ini
    """
    config = ConfigParser()
    config.read("config.ini")
    return config


def download_file_from_url(url: str, filename: str, headers: dict = None) -> None:
    """
    Downloads a file from the given URL and saves it to the specified filename.
    Optionally accepts headers for the request.
    """

    req = Request(url=url, headers=headers or {})
    with urlopen(req) as response:
        data = response.read()
        with open(filename, "wb") as f:
            f.write(data)


def has_enough_credits(user_credits: int, deduction: int) -> bool:
    """
    Check to see if the user has enough credits to use the model
    """
    return user_credits - deduction >= 0


def construct_error_embed(
    context: CommandContext, user_input: Optional[str] = "", fields: Optional[dict] = None
) -> Embed:
    description = ""

    if user_input:
        description += f"User Input:\n> {user_input}"

    embed = Embed(title="B4NG AI Generation Error", color=15548997)
    embed.add_field(name="User", value=f"<@{context.user_id}>")

    if fields:
        for field in fields:
            embed.add_field(name=field, value=fields[field])

    embed.description = description

    return embed


async def get_openai_client(guild_id: int) -> AsyncOpenAI:
    """
    Return the guild-assigned API key
    """
    api_key = await get_api_key(guild_id=guild_id)
    openai_client = AsyncOpenAI(api_key=api_key)

    return openai_client


async def new_response(
    context: CommandContext,
    prompt: str,
    instructions: Optional[str] = None,
    openai_client: Optional[AsyncOpenAI] = None,
    max_output_tokens: int = 1000,
    model: str = "gpt-4.1-mini",
) -> Response:
    """
    Generate a new response with the OpenAI Response API and store its ID
    """

    # topic-specific models
    if context.params.get("topic") == "talk_quotes":
        model = "gpt-4o"

    if not openai_client:
        openai_client = await get_openai_client(guild_id=context.guild_id)

    previous_response_id = await get_response_id(context=context)

    response = await openai_client.responses.create(
        input=prompt,
        model=model,
        instructions=instructions,
        max_output_tokens=max_output_tokens,
        previous_response_id=previous_response_id,
    )

    if context.params.get("topic"):
        await update_chat(response_id=response.id, context=context)

    return response


async def generate_speech(
    context: CommandContext,
    file_name: str,
    tts: str,
    voice: str = "onyx",
    openai_client: Optional[AsyncOpenAI] = None,
) -> Path:
    """
    Use OpenAI's Speech API to create a text-to-speech audio file
    """
    config = get_config()

    if not openai_client:
        openai_client = await get_openai_client(guild_id=context.guild_id)

    async with openai_client.audio.speech.with_streaming_response.create(
        model=config.get("OPENAI_GENERAL", "speech_model", fallback="tts-1"),
        voice=voice,
        input=tts,
        response_format=config.get("OPENAI_GENERAL", "speech_file_format", fallback="wav"),
    ) as speech:
        file_path = content_path(context=context, file_name=file_name)
        await speech.stream_to_file(file_path)

    return file_path


async def speak_and_spell(
    context: CommandContext,
    prompt: str,
) -> Tuple[str, Path]:
    """
    Create a new response and WAV file in one nice function.
    """

    config = get_config()

    openai_client = await get_openai_client(guild_id=context.guild_id)

    instructions = config.get("OPENAI_INSTRUCTIONS", context.params.get("topic"))

    response = await new_response(
        context=context, prompt=prompt, instructions=instructions, openai_client=openai_client
    )

    tts = response.output_text

    file_path = await generate_speech(
        context=context, tts=tts, file_name=f"{response.id}.wav", openai_client=openai_client
    )

    return tts, file_path


def content_path(context: CommandContext, file_name: str) -> Path:
    """
    Create a path to store the content generated by OpenAI.
    """
    ts = datetime.now().strftime(format="%Y-%m-%d - %A")
    dir_path = Path(f"generated_content/guild_{context.guild_id}/{ts}/{context.command_name}")
    dir_path.mkdir(parents=True, exist_ok=True)
    return dir_path / file_name
